{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_date</th>\n",
       "      <th>gross_amount</th>\n",
       "      <th>gross_cost</th>\n",
       "      <th>margin</th>\n",
       "      <th>tax_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>391.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.5</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>365.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>156.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>786.6</td>\n",
       "      <td>125.0</td>\n",
       "      <td>661.6</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     txn_date  gross_amount  gross_cost  margin  tax_amount\n",
       "0  2020-05-19         391.5         0.0   391.5        10.5\n",
       "1  2020-06-19         365.0       125.0   240.0        22.0\n",
       "2  2020-06-26         156.0        81.0    75.0         0.0\n",
       "3  2020-07-16          75.0         0.0    75.0         0.0\n",
       "4  2020-07-17         786.6       125.0   661.6        44.4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tfv1\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"universe_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns after removing missing values: (18, 2)\n",
      "The time series starts from:  2020-05-19 00:00:00\n",
      "The time series ends on:  2020-09-03 00:00:00\n",
      "\n",
      "\n",
      "CPU times: user 9.76 ms, sys: 178 Âµs, total: 9.94 ms\n",
      "Wall time: 48.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['txn_date'] = pd.to_datetime(df['txn_date'])\n",
    "\n",
    "df = df.loc[:, [\"txn_date\", \"gross_amount\"]]\n",
    "df.sort_values('txn_date', inplace=True, ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print('Number of rows and columns after removing missing values:', df.shape)\n",
    "print('The time series starts from: ', df['txn_date'].min())\n",
    "print('The time series ends on: ', df['txn_date'].max())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   txn_date      18 non-null     datetime64[ns]\n",
      " 1   gross_amount  18 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 416.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dates: 2020-08-29 00:00:00 to 2020-09-03 00:00:00\n",
      "Validation dates: 2020-08-18 00:00:00 to 2020-08-25 00:00:00\n",
      "Train dates: 2020-05-19 00:00:00 to 2020-08-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split into training, validation and test datasets.\n",
    "# Since it's timeseries we should do it by date.\n",
    "test_cutoff_date = df['txn_date'].max() - timedelta(days=7)\n",
    "val_cutoff_date = test_cutoff_date - timedelta(days=14)\n",
    "\n",
    "df_test = df[df['txn_date'] > test_cutoff_date]\n",
    "df_val = df[(df['txn_date'] > val_cutoff_date) & (df['txn_date'] <= test_cutoff_date)]\n",
    "df_train = df[df['txn_date'] <= val_cutoff_date]\n",
    "\n",
    "#check out the datasets\n",
    "print('Test dates: {} to {}'.format(df_test['txn_date'].min(), df_test['txn_date'].max()))\n",
    "print('Validation dates: {} to {}'.format(df_val['txn_date'].min(), df_val['txn_date'].max()))\n",
    "print('Train dates: {} to {}'.format(df_train['txn_date'].min(), df_train['txn_date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 2), (6, 2), (4, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 files.\n",
      "ts_data/ts_file_0.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_lag_7</th>\n",
       "      <th>x_lag_6</th>\n",
       "      <th>x_lag_5</th>\n",
       "      <th>x_lag_4</th>\n",
       "      <th>x_lag_3</th>\n",
       "      <th>x_lag_2</th>\n",
       "      <th>x_lag_1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.351667</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x_lag_7   x_lag_6   x_lag_5   x_lag_4   x_lag_3   x_lag_2   x_lag_1  \\\n",
       "0  0.322222  0.090000  0.000000  0.790667  0.005111  1.000000  0.472222   \n",
       "1  0.090000  0.000000  0.790667  0.005111  1.000000  0.472222  0.351667   \n",
       "2  0.000000  0.790667  0.005111  1.000000  0.472222  0.351667  0.322222   \n",
       "3  0.790667  0.005111  1.000000  0.472222  0.351667  0.322222  0.090000   \n",
       "4  0.005111  1.000000  0.472222  0.351667  0.322222  0.090000  0.000000   \n",
       "5  1.000000  0.472222  0.351667  0.322222  0.090000  0.000000  0.790667   \n",
       "6  0.472222  0.351667  0.322222  0.090000  0.000000  0.790667  0.005111   \n",
       "7  0.351667  0.322222  0.090000  0.000000  0.790667  0.005111  1.000000   \n",
       "\n",
       "          y  \n",
       "0  0.351667  \n",
       "1  0.322222  \n",
       "2  0.090000  \n",
       "3  0.000000  \n",
       "4  0.790667  \n",
       "5  0.005111  \n",
       "6  1.000000  \n",
       "7  0.472222  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "# Goal of the model:\n",
    "#  Predict Global_active_power at a specified time in the future.\n",
    "#   Eg. We want to predict how much Global_active_power will be ten minutes from now.\n",
    "#       We can use all the values from t-1, t-2, t-3, .... t-history_length to predict t+10\n",
    "\n",
    "def create_ts_files(dataset, start_index, end_index, history_length, step_size, target_step, num_rows_per_file, data_folder):\n",
    "    assert step_size > 0\n",
    "    assert start_index >= 0\n",
    "    \n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "        \n",
    "    time_lags = sorted(range(target_step + 1, target_step + history_length + 1, step_size), reverse=True)\n",
    "    col_names = [f\"x_lag_{i}\" for i in time_lags] + [\"y\"]\n",
    "    \n",
    "    start_index = start_index + history_length\n",
    "    \n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_step\n",
    "        \n",
    "    rng = range(start_index, end_index)\n",
    "    num_rows = len(rng)\n",
    "    num_files = math.ceil(num_rows / num_rows_per_file)\n",
    "    \n",
    "    # for each file.\n",
    "    print(f'Creating {num_files} files.')\n",
    "    \n",
    "    for i in range(num_files):\n",
    "        filename = f\"{data_folder}/ts_file_{i}.pkl\"\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            print(f\"{filename}\")\n",
    "            \n",
    "        # get the start and end index\n",
    "        ind0 = i * num_rows_per_file\n",
    "        ind1 = min(ind0 + num_rows_per_file, end_index)\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        # j in the current timestep. Will need j-n to j-1 for the history. And j + target_step for the target.\n",
    "        for j in range(ind0, ind1):\n",
    "            indices = range(j - 1,  j-history_length - 1, -step_size)\n",
    "            data = dataset[sorted(indices) + [j + target_step]]\n",
    "            \n",
    "            # append data to the list\n",
    "            data_list.append(data)\n",
    "            \n",
    "        df_ts = pd.DataFrame(data_list, columns=col_names)     \n",
    "        display(df_ts)\n",
    "        df_ts.to_pickle(filename)\n",
    "        \n",
    "    return len(col_names) - 1\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 60 # 2 months data per_file.\n",
    "gross_amount = df_train['gross_amount'].values\n",
    "\n",
    "# Scaled to work with Neural networks.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "gross_amount_scaled = scaler.fit_transform(gross_amount.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "\n",
    "history_length = 7 # The history length in days.\n",
    "step_size = 1 # The sampling rate of the history. Eg. If step_size = 1, then values from every day will be in the history.\n",
    "                #                                       If step size = 10 then values every 10 days will be in the history.\n",
    "target_step = 0  # The time step in the future to predict. Eg. If target_step = 0, then predict the next day after the end of the history period.\n",
    "                  #                                             If target_step = 10 then predict 10 days the next timestep (11 days after the end of history).\n",
    "\n",
    "# The csv creation returns the number of rows and number of features. We need these values below.\n",
    "num_timesteps = create_ts_files(gross_amount_scaled, start_index=0, end_index=None, history_length=history_length, step_size=step_size, \n",
    "                                target_step=target_step, num_rows_per_file=batch_size*1, data_folder='ts_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# So we can handle loading the data in chunks from the hard drive instead of having to load everything into memory.\n",
    "# \n",
    "# The reason we want to do this is so we can do custom processing on the data that we are feeding into the LSTM.\n",
    "# LSTM requires a certain shape and it is tricky to get it right.\n",
    "#\n",
    "\n",
    "class TimeSeriesLoader:\n",
    "    def __init__(self, ts_folder, filename_format):\n",
    "        self.ts_folder = ts_folder\n",
    "        \n",
    "        # find the number of files\n",
    "        i = 0\n",
    "        file_found = True\n",
    "        \n",
    "        while file_found:\n",
    "            filename = self.ts_folder + \"/\" + filename_format.format(i)\n",
    "            file_found = os.path.exists(filename)\n",
    "                       \n",
    "            if file_found:\n",
    "                i += 1\n",
    "        \n",
    "        self.num_files = i\n",
    "        self.files_indices = np.arange(self.num_files)\n",
    "        self.shuffle_chunks()\n",
    "        \n",
    "    def num_chunks(self):\n",
    "        return self.num_files\n",
    "    \n",
    "    def get_chunk(self, idx):\n",
    "        assert (idx >= 0) and (idx < self.num_files)\n",
    "        \n",
    "        ind = self.files_indices[idx]\n",
    "        filename = self.ts_folder + \"/\" + filename_format.format(ind)\n",
    "        \n",
    "        df_ts = pd.read_pickle(filename)\n",
    "        num_records = len(df_ts.index)\n",
    "        \n",
    "        features = df_ts.drop(\"y\", axis=1).values\n",
    "        target = df_ts[\"y\"].values\n",
    "        \n",
    "        # Reshape for input into LSTM. Batch major format.\n",
    "        features_batchmajor = np.array(features).reshape(num_records, -1 , 1)\n",
    "        return features_batchmajor, target\n",
    "    \n",
    "    \n",
    "    # this shuffles the order the chunks will be outputted from get_chunk.\n",
    "    def shuffle_chunks(self):\n",
    "        np.random.shuffle(self.files_indices) \n",
    "            \n",
    "ts_folder = 'ts_data'\n",
    "filename_format = 'ts_file_{}.pkl'\n",
    "tss = TimeSeriesLoader(ts_folder, filename_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Keras model.\n",
    "# Use hyperparameter optimization if you have the time.\n",
    "\n",
    "ts_inputs = tf.keras.Input(shape=(num_timesteps, 1))\n",
    "\n",
    "# units=10 -> The cell and hidden states will be of dimension 10.\n",
    "#             The number of parameters that need to be trained = 4*units*(units+2)\n",
    "\n",
    "x = layers.LSTM(units=10)(ts_inputs)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss=tf.keras.losses.MeanSquaredError(), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4074 - mse: 0.4074\n",
      "epoch #1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4178 - mse: 0.4178\n",
      "epoch #2\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3397 - mse: 0.3397\n",
      "epoch #3\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2880 - mse: 0.2880\n",
      "epoch #4\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2764 - mse: 0.2764\n",
      "epoch #5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2498 - mse: 0.2498\n",
      "epoch #6\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3072 - mse: 0.3072\n",
      "epoch #7\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2315 - mse: 0.2315\n",
      "epoch #8\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2302 - mse: 0.2302\n",
      "epoch #9\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2245 - mse: 0.2245\n",
      "epoch #10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2134 - mse: 0.2134\n",
      "epoch #11\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1885 - mse: 0.1885\n",
      "epoch #12\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1715 - mse: 0.1715\n",
      "epoch #13\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1724 - mse: 0.1724\n",
      "epoch #14\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1736 - mse: 0.1736\n",
      "epoch #15\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1728 - mse: 0.1728\n",
      "epoch #16\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1790 - mse: 0.1790\n",
      "epoch #17\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1557 - mse: 0.1557\n",
      "epoch #18\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1385 - mse: 0.1385\n",
      "epoch #19\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1379 - mse: 0.1379\n",
      "epoch #20\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1385 - mse: 0.1385\n",
      "epoch #21\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1187 - mse: 0.1187\n",
      "epoch #22\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1145 - mse: 0.1145\n",
      "epoch #23\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.1225\n",
      "epoch #24\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1404 - mse: 0.1404\n",
      "epoch #25\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1287 - mse: 0.1287\n",
      "epoch #26\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1343 - mse: 0.1343\n",
      "epoch #27\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1043 - mse: 0.1043\n",
      "epoch #28\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1254 - mse: 0.1254\n",
      "epoch #29\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0958 - mse: 0.0958\n",
      "epoch #30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1211 - mse: 0.1211\n",
      "epoch #31\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1466 - mse: 0.1466\n",
      "epoch #32\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1049 - mse: 0.1049\n",
      "epoch #33\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1011 - mse: 0.1011\n",
      "epoch #34\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1170 - mse: 0.1170\n",
      "epoch #35\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1027 - mse: 0.1027\n",
      "epoch #36\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1320 - mse: 0.1320\n",
      "epoch #37\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.1181\n",
      "epoch #38\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1007 - mse: 0.1007\n",
      "epoch #39\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1236 - mse: 0.1236\n",
      "epoch #40\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1107 - mse: 0.1107\n",
      "epoch #41\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1059 - mse: 0.1059\n",
      "epoch #42\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1101 - mse: 0.1101\n",
      "epoch #43\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1363 - mse: 0.1363\n",
      "epoch #44\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.1169\n",
      "epoch #45\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1075 - mse: 0.1075\n",
      "epoch #46\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1221 - mse: 0.1221\n",
      "epoch #47\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1006 - mse: 0.1006\n",
      "epoch #48\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1144 - mse: 0.1144\n",
      "epoch #49\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1322 - mse: 0.1322\n",
      "epoch #50\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0906 - mse: 0.0906\n",
      "epoch #51\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1014 - mse: 0.1014\n",
      "epoch #52\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141 - mse: 0.1141\n",
      "epoch #53\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1020 - mse: 0.1020\n",
      "epoch #54\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1047 - mse: 0.1047\n",
      "epoch #55\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1115 - mse: 0.1115\n",
      "epoch #56\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1283 - mse: 0.1283\n",
      "epoch #57\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1309 - mse: 0.1309\n",
      "epoch #58\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0978 - mse: 0.0978\n",
      "epoch #59\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1132 - mse: 0.1132\n",
      "epoch #60\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1221 - mse: 0.1221\n",
      "epoch #61\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0886 - mse: 0.0886\n",
      "epoch #62\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1034 - mse: 0.1034\n",
      "epoch #63\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1212 - mse: 0.1212\n",
      "epoch #64\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1209 - mse: 0.1209\n",
      "epoch #65\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0872\n",
      "epoch #66\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1207 - mse: 0.1207\n",
      "epoch #67\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1367 - mse: 0.1367\n",
      "epoch #68\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1276 - mse: 0.1276\n",
      "epoch #69\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1493 - mse: 0.1493\n",
      "epoch #70\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1035 - mse: 0.1035\n",
      "epoch #71\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1196 - mse: 0.1196\n",
      "epoch #72\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1152 - mse: 0.1152\n",
      "epoch #73\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1184 - mse: 0.1184\n",
      "epoch #74\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1011 - mse: 0.1011\n",
      "epoch #75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1144 - mse: 0.1144\n",
      "epoch #76\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1308 - mse: 0.1308\n",
      "epoch #77\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1044 - mse: 0.1044\n",
      "epoch #78\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0879 - mse: 0.0879\n",
      "epoch #79\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0962 - mse: 0.0962\n",
      "epoch #80\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1185 - mse: 0.1185\n",
      "epoch #81\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1013 - mse: 0.1013\n",
      "epoch #82\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1145 - mse: 0.1145\n",
      "epoch #83\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0905 - mse: 0.0905\n",
      "epoch #84\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0923 - mse: 0.0923\n",
      "epoch #85\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1155 - mse: 0.1155\n",
      "epoch #86\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1022 - mse: 0.1022\n",
      "epoch #87\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1208 - mse: 0.1208\n",
      "epoch #88\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1054 - mse: 0.1054\n",
      "epoch #89\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1075 - mse: 0.1075\n",
      "epoch #90\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0927 - mse: 0.0927\n",
      "epoch #91\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1044 - mse: 0.1044\n",
      "epoch #92\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1134 - mse: 0.1134\n",
      "epoch #93\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0911 - mse: 0.0911\n",
      "epoch #94\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1423 - mse: 0.1423\n",
      "epoch #95\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0988 - mse: 0.0988\n",
      "epoch #96\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1368 - mse: 0.1368\n",
      "epoch #97\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1144 - mse: 0.1144\n",
      "epoch #98\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0964 - mse: 0.0964\n",
      "epoch #99\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1104 - mse: 0.1104\n",
      "epoch #100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1007 - mse: 0.1007\n",
      "epoch #101\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1224 - mse: 0.1224\n",
      "epoch #102\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1147 - mse: 0.1147\n",
      "epoch #103\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1159 - mse: 0.1159\n",
      "epoch #104\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1071 - mse: 0.1071\n",
      "epoch #105\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0961 - mse: 0.0961\n",
      "epoch #106\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1140 - mse: 0.1140\n",
      "epoch #107\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1051 - mse: 0.1051\n",
      "epoch #108\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1158 - mse: 0.1158\n",
      "epoch #109\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1267 - mse: 0.1267\n",
      "epoch #110\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1264 - mse: 0.1264\n",
      "epoch #111\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1306 - mse: 0.1306\n",
      "epoch #112\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0983 - mse: 0.0983\n",
      "epoch #113\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1197 - mse: 0.1197\n",
      "epoch #114\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1049 - mse: 0.1049\n",
      "epoch #115\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1215 - mse: 0.1215\n",
      "epoch #116\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1187 - mse: 0.1187\n",
      "epoch #117\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1082 - mse: 0.1082\n",
      "epoch #118\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1073 - mse: 0.1073\n",
      "epoch #119\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1035 - mse: 0.1035\n",
      "epoch #120\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0817 - mse: 0.0817\n",
      "epoch #121\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1236 - mse: 0.1236\n",
      "epoch #122\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1244 - mse: 0.1244\n",
      "epoch #123\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0945 - mse: 0.0945\n",
      "epoch #124\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0950 - mse: 0.0950\n",
      "epoch #125\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0964 - mse: 0.0964\n",
      "epoch #126\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0988 - mse: 0.0988\n",
      "epoch #127\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.1294\n",
      "epoch #128\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1350 - mse: 0.1350\n",
      "epoch #129\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1293 - mse: 0.1293\n",
      "epoch #130\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1263 - mse: 0.1263\n",
      "epoch #131\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1194 - mse: 0.1194\n",
      "epoch #132\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1051 - mse: 0.1051\n",
      "epoch #133\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1197 - mse: 0.1197\n",
      "epoch #134\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1207 - mse: 0.1207\n",
      "epoch #135\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1078 - mse: 0.1078\n",
      "epoch #136\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1234 - mse: 0.1234\n",
      "epoch #137\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1177 - mse: 0.1177\n",
      "epoch #138\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1182 - mse: 0.1182\n",
      "epoch #139\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1054 - mse: 0.1054\n",
      "epoch #140\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1028 - mse: 0.1028\n",
      "epoch #141\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0961 - mse: 0.0961\n",
      "epoch #142\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0841 - mse: 0.0841\n",
      "epoch #143\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1156 - mse: 0.1156\n",
      "epoch #144\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1422 - mse: 0.1422\n",
      "epoch #145\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1176 - mse: 0.1176\n",
      "epoch #146\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0998 - mse: 0.0998\n",
      "epoch #147\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1242 - mse: 0.1242\n",
      "epoch #148\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1082 - mse: 0.1082\n",
      "epoch #149\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1233 - mse: 0.1233\n",
      "epoch #150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0947\n",
      "epoch #151\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1119 - mse: 0.1119\n",
      "epoch #152\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0959 - mse: 0.0959\n",
      "epoch #153\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1149 - mse: 0.1149\n",
      "epoch #154\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0909 - mse: 0.0909\n",
      "epoch #155\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1121 - mse: 0.1121\n",
      "epoch #156\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0973 - mse: 0.0973\n",
      "epoch #157\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1281 - mse: 0.1281\n",
      "epoch #158\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0888 - mse: 0.0888\n",
      "epoch #159\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1174 - mse: 0.1174\n",
      "epoch #160\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0760 - mse: 0.0760\n",
      "epoch #161\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1087 - mse: 0.1087\n",
      "epoch #162\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0986 - mse: 0.0986\n",
      "epoch #163\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1219 - mse: 0.1219\n",
      "epoch #164\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0976 - mse: 0.0976\n",
      "epoch #165\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1139 - mse: 0.1139\n",
      "epoch #166\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1183 - mse: 0.1183\n",
      "epoch #167\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1020 - mse: 0.1020\n",
      "epoch #168\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1105 - mse: 0.1105\n",
      "epoch #169\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1011 - mse: 0.1011\n",
      "epoch #170\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1262 - mse: 0.1262\n",
      "epoch #171\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0945 - mse: 0.0945\n",
      "epoch #172\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1176 - mse: 0.1176\n",
      "epoch #173\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1090 - mse: 0.1090\n",
      "epoch #174\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1131 - mse: 0.1131\n",
      "epoch #175\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0952 - mse: 0.0952\n",
      "epoch #176\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1066 - mse: 0.1066\n",
      "epoch #177\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0927 - mse: 0.0927\n",
      "epoch #178\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0959 - mse: 0.0959\n",
      "epoch #179\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1262 - mse: 0.1262\n",
      "epoch #180\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.1062\n",
      "epoch #181\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1043 - mse: 0.1043\n",
      "epoch #182\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0973 - mse: 0.0973\n",
      "epoch #183\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1236 - mse: 0.1236\n",
      "epoch #184\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0994 - mse: 0.0994\n",
      "epoch #185\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1002 - mse: 0.1002\n",
      "epoch #186\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1076 - mse: 0.1076\n",
      "epoch #187\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0986 - mse: 0.0986\n",
      "epoch #188\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0796 - mse: 0.0796\n",
      "epoch #189\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0969 - mse: 0.0969\n",
      "epoch #190\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1095 - mse: 0.1095\n",
      "epoch #191\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1168 - mse: 0.1168\n",
      "epoch #192\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1085 - mse: 0.1085\n",
      "epoch #193\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1316 - mse: 0.1316\n",
      "epoch #194\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1003 - mse: 0.1003\n",
      "epoch #195\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1199 - mse: 0.1199\n",
      "epoch #196\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1010 - mse: 0.1010\n",
      "epoch #197\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1175 - mse: 0.1175\n",
      "epoch #198\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0897 - mse: 0.0897\n",
      "epoch #199\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1084 - mse: 0.1084\n",
      "epoch #200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1282 - mse: 0.1282\n",
      "epoch #201\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1128 - mse: 0.1128\n",
      "epoch #202\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1212 - mse: 0.1212\n",
      "epoch #203\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0842 - mse: 0.0842\n",
      "epoch #204\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1099 - mse: 0.1099\n",
      "epoch #205\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1463 - mse: 0.1463\n",
      "epoch #206\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1208 - mse: 0.1208\n",
      "epoch #207\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1065 - mse: 0.1065\n",
      "epoch #208\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0896 - mse: 0.0896\n",
      "epoch #209\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0939 - mse: 0.0939\n",
      "epoch #210\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0957 - mse: 0.0957\n",
      "epoch #211\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1126 - mse: 0.1126\n",
      "epoch #212\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1248 - mse: 0.1248\n",
      "epoch #213\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1035 - mse: 0.1035\n",
      "epoch #214\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1085 - mse: 0.1085\n",
      "epoch #215\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0982 - mse: 0.0982\n",
      "epoch #216\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1166 - mse: 0.1166\n",
      "epoch #217\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1032 - mse: 0.1032\n",
      "epoch #218\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.1062\n",
      "epoch #219\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1121 - mse: 0.1121\n",
      "epoch #220\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1267 - mse: 0.1267\n",
      "epoch #221\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1144 - mse: 0.1144\n",
      "epoch #222\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1111 - mse: 0.1111\n",
      "epoch #223\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1190 - mse: 0.1190\n",
      "epoch #224\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1091 - mse: 0.1091\n",
      "epoch #225\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0994 - mse: 0.0994\n",
      "epoch #226\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1153 - mse: 0.1153\n",
      "epoch #227\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1188 - mse: 0.1188\n",
      "epoch #228\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0939 - mse: 0.0939\n",
      "epoch #229\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1016 - mse: 0.1016\n",
      "epoch #230\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0922 - mse: 0.0922\n",
      "epoch #231\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0966 - mse: 0.0966\n",
      "epoch #232\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1116 - mse: 0.1116\n",
      "epoch #233\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1117 - mse: 0.1117\n",
      "epoch #234\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1068 - mse: 0.1068\n",
      "epoch #235\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1396 - mse: 0.1396\n",
      "epoch #236\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1301 - mse: 0.1301\n",
      "epoch #237\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.1072\n",
      "epoch #238\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1037 - mse: 0.1037\n",
      "epoch #239\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1009 - mse: 0.1009\n",
      "epoch #240\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0959 - mse: 0.0959\n",
      "epoch #241\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0974 - mse: 0.0974\n",
      "epoch #242\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1124 - mse: 0.1124\n",
      "epoch #243\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1068 - mse: 0.1068\n",
      "epoch #244\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1102 - mse: 0.1102\n",
      "epoch #245\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1077 - mse: 0.1077\n",
      "epoch #246\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0943 - mse: 0.0943\n",
      "epoch #247\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1065 - mse: 0.1065\n",
      "epoch #248\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1094 - mse: 0.1094\n",
      "epoch #249\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1084 - mse: 0.1084\n",
      "epoch #250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0938 - mse: 0.0938\n",
      "epoch #251\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0940 - mse: 0.0940\n",
      "epoch #252\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1016 - mse: 0.1016\n",
      "epoch #253\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1022 - mse: 0.1022\n",
      "epoch #254\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1223 - mse: 0.1223\n",
      "epoch #255\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1047 - mse: 0.1047\n",
      "epoch #256\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1111 - mse: 0.1111\n",
      "epoch #257\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1003 - mse: 0.1003\n",
      "epoch #258\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1027 - mse: 0.1027\n",
      "epoch #259\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1141 - mse: 0.1141\n",
      "epoch #260\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1013 - mse: 0.1013\n",
      "epoch #261\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1239 - mse: 0.1239\n",
      "epoch #262\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0972 - mse: 0.0972\n",
      "epoch #263\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1111 - mse: 0.1111\n",
      "epoch #264\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1309 - mse: 0.1309\n",
      "epoch #265\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0859 - mse: 0.0859\n",
      "epoch #266\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1014 - mse: 0.1014\n",
      "epoch #267\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1025 - mse: 0.1025\n",
      "epoch #268\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1094 - mse: 0.1094\n",
      "epoch #269\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0882 - mse: 0.0882\n",
      "epoch #270\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1025 - mse: 0.1025\n",
      "epoch #271\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1042 - mse: 0.1042\n",
      "epoch #272\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1152 - mse: 0.1152\n",
      "epoch #273\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0938 - mse: 0.0938\n",
      "epoch #274\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0995 - mse: 0.0995\n",
      "epoch #275\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1048 - mse: 0.1048\n",
      "epoch #276\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0968 - mse: 0.0968\n",
      "epoch #277\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0971 - mse: 0.0971\n",
      "epoch #278\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1124 - mse: 0.1124\n",
      "epoch #279\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1023 - mse: 0.1023\n",
      "epoch #280\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1016 - mse: 0.1016\n",
      "epoch #281\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0944 - mse: 0.0944\n",
      "epoch #282\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1142 - mse: 0.1142\n",
      "epoch #283\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1012 - mse: 0.1012\n",
      "epoch #284\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0988 - mse: 0.0988\n",
      "epoch #285\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0940 - mse: 0.0940\n",
      "epoch #286\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1114 - mse: 0.1114\n",
      "epoch #287\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1032 - mse: 0.1032\n",
      "epoch #288\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0944 - mse: 0.0944\n",
      "epoch #289\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0987 - mse: 0.0987\n",
      "epoch #290\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0781 - mse: 0.0781\n",
      "epoch #291\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1255 - mse: 0.1255\n",
      "epoch #292\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0937 - mse: 0.0937\n",
      "epoch #293\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1017 - mse: 0.1017\n",
      "epoch #294\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1077 - mse: 0.1077\n",
      "epoch #295\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0962 - mse: 0.0962\n",
      "epoch #296\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1015 - mse: 0.1015\n",
      "epoch #297\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1075 - mse: 0.1075\n",
      "epoch #298\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1069 - mse: 0.1069\n",
      "epoch #299\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1054 - mse: 0.1054\n",
      "epoch #300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1179 - mse: 0.1179\n",
      "epoch #301\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0997 - mse: 0.0997\n",
      "epoch #302\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1208 - mse: 0.1208\n",
      "epoch #303\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0947 - mse: 0.0947\n",
      "epoch #304\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0876 - mse: 0.0876\n",
      "epoch #305\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1271 - mse: 0.1271\n",
      "epoch #306\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1037 - mse: 0.1037\n",
      "epoch #307\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1100 - mse: 0.1100\n",
      "epoch #308\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0912\n",
      "epoch #309\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.1099\n",
      "epoch #310\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1081 - mse: 0.1081\n",
      "epoch #311\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1306 - mse: 0.1306\n",
      "epoch #312\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1059 - mse: 0.1059\n",
      "epoch #313\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1042 - mse: 0.1042\n",
      "epoch #314\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0886 - mse: 0.0886\n",
      "epoch #315\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0896 - mse: 0.0896\n",
      "epoch #316\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0794 - mse: 0.0794\n",
      "epoch #317\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1013 - mse: 0.1013\n",
      "epoch #318\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0859 - mse: 0.0859\n",
      "epoch #319\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1036 - mse: 0.1036\n",
      "epoch #320\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1120 - mse: 0.1120\n",
      "epoch #321\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1144 - mse: 0.1144\n",
      "epoch #322\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1146 - mse: 0.1146\n",
      "epoch #323\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0874 - mse: 0.0874\n",
      "epoch #324\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1052 - mse: 0.1052\n",
      "epoch #325\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1116 - mse: 0.1116\n",
      "epoch #326\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1047 - mse: 0.1047\n",
      "epoch #327\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1057 - mse: 0.1057\n",
      "epoch #328\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1093 - mse: 0.1093\n",
      "epoch #329\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0986 - mse: 0.0986\n",
      "epoch #330\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0955 - mse: 0.0955\n",
      "epoch #331\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0972 - mse: 0.0972\n",
      "epoch #332\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0894 - mse: 0.0894\n",
      "epoch #333\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1182 - mse: 0.1182\n",
      "epoch #334\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0927 - mse: 0.0927\n",
      "epoch #335\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0894 - mse: 0.0894\n",
      "epoch #336\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0956 - mse: 0.0956\n",
      "epoch #337\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1165 - mse: 0.1165\n",
      "epoch #338\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1035 - mse: 0.1035\n",
      "epoch #339\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0956 - mse: 0.0956\n",
      "epoch #340\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1150 - mse: 0.1150\n",
      "epoch #341\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0996 - mse: 0.0996\n",
      "epoch #342\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0951 - mse: 0.0951\n",
      "epoch #343\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1109 - mse: 0.1109\n",
      "epoch #344\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0987 - mse: 0.0987\n",
      "epoch #345\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1188 - mse: 0.1188\n",
      "epoch #346\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0995 - mse: 0.0995\n",
      "epoch #347\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0995 - mse: 0.0995\n",
      "epoch #348\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0940 - mse: 0.0940\n",
      "epoch #349\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1091 - mse: 0.1091\n",
      "epoch #350\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1058 - mse: 0.1058\n",
      "epoch #351\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0985 - mse: 0.0985\n",
      "epoch #352\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1132 - mse: 0.1132\n",
      "epoch #353\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1057 - mse: 0.1057\n",
      "epoch #354\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1049 - mse: 0.1049\n",
      "epoch #355\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1153 - mse: 0.1153\n",
      "epoch #356\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1073 - mse: 0.1073\n",
      "epoch #357\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0972 - mse: 0.0972\n",
      "epoch #358\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1075 - mse: 0.1075\n",
      "epoch #359\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0915 - mse: 0.0915\n",
      "epoch #360\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0978 - mse: 0.0978\n",
      "epoch #361\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1013 - mse: 0.1013\n",
      "epoch #362\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0791 - mse: 0.0791\n",
      "epoch #363\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0982\n",
      "epoch #364\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1067 - mse: 0.1067\n",
      "epoch #365\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0928 - mse: 0.0928\n",
      "epoch #366\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0954 - mse: 0.0954\n",
      "epoch #367\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1084 - mse: 0.1084\n",
      "epoch #368\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0880 - mse: 0.0880\n",
      "epoch #369\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0985 - mse: 0.0985\n",
      "epoch #370\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1090 - mse: 0.1090\n",
      "epoch #371\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0952 - mse: 0.0952\n",
      "epoch #372\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0983 - mse: 0.0983\n",
      "epoch #373\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1036 - mse: 0.1036\n",
      "epoch #374\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1157 - mse: 0.1157\n",
      "epoch #375\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0940 - mse: 0.0940\n",
      "epoch #376\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0896 - mse: 0.0896\n",
      "epoch #377\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1070 - mse: 0.1070\n",
      "epoch #378\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1055 - mse: 0.1055\n",
      "epoch #379\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1060 - mse: 0.1060\n",
      "epoch #380\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0928 - mse: 0.0928\n",
      "epoch #381\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0842 - mse: 0.0842\n",
      "epoch #382\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1100 - mse: 0.1100\n",
      "epoch #383\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0977 - mse: 0.0977\n",
      "epoch #384\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1144 - mse: 0.1144\n",
      "epoch #385\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0989 - mse: 0.0989\n",
      "epoch #386\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0840 - mse: 0.0840\n",
      "epoch #387\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0998 - mse: 0.0998\n",
      "epoch #388\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0979 - mse: 0.0979\n",
      "epoch #389\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0968 - mse: 0.0968\n",
      "epoch #390\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0896 - mse: 0.0896\n",
      "epoch #391\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0973 - mse: 0.0973\n",
      "epoch #392\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1154 - mse: 0.1154\n",
      "epoch #393\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1150 - mse: 0.1150\n",
      "epoch #394\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1072 - mse: 0.1072\n",
      "epoch #395\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1130 - mse: 0.1130\n",
      "epoch #396\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1004 - mse: 0.1004\n",
      "epoch #397\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0829 - mse: 0.0829\n",
      "epoch #398\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0972 - mse: 0.0972\n",
      "epoch #399\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0802 - mse: 0.0802\n",
      "epoch #400\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0908 - mse: 0.0908\n",
      "epoch #401\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1236 - mse: 0.1236\n",
      "epoch #402\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1050 - mse: 0.1050\n",
      "epoch #403\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1004 - mse: 0.1004\n",
      "epoch #404\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1015 - mse: 0.1015\n",
      "epoch #405\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0927 - mse: 0.0927\n",
      "epoch #406\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1099 - mse: 0.1099\n",
      "epoch #407\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1159 - mse: 0.1159\n",
      "epoch #408\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0966 - mse: 0.0966\n",
      "epoch #409\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1080 - mse: 0.1080\n",
      "epoch #410\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1096 - mse: 0.1096\n",
      "epoch #411\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0965 - mse: 0.0965\n",
      "epoch #412\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1076 - mse: 0.1076\n",
      "epoch #413\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1111 - mse: 0.1111\n",
      "epoch #414\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0963 - mse: 0.0963\n",
      "epoch #415\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0992\n",
      "epoch #416\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1012 - mse: 0.1012\n",
      "epoch #417\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1001 - mse: 0.1001\n",
      "epoch #418\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1018 - mse: 0.1018\n",
      "epoch #419\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1150 - mse: 0.1150\n",
      "epoch #420\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1108 - mse: 0.1108\n",
      "epoch #421\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0981 - mse: 0.0981\n",
      "epoch #422\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1035 - mse: 0.1035\n",
      "epoch #423\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0825 - mse: 0.0825\n",
      "epoch #424\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1037 - mse: 0.1037\n",
      "epoch #425\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0990 - mse: 0.0990\n",
      "epoch #426\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0906 - mse: 0.0906\n",
      "epoch #427\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0834 - mse: 0.0834\n",
      "epoch #428\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0844 - mse: 0.0844\n",
      "epoch #429\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1011 - mse: 0.1011\n",
      "epoch #430\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0954 - mse: 0.0954\n",
      "epoch #431\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0880 - mse: 0.0880\n",
      "epoch #432\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1042 - mse: 0.1042\n",
      "epoch #433\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1031 - mse: 0.1031\n",
      "epoch #434\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0943 - mse: 0.0943\n",
      "epoch #435\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1072 - mse: 0.1072\n",
      "epoch #436\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0911 - mse: 0.0911\n",
      "epoch #437\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1051 - mse: 0.1051\n",
      "epoch #438\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1021 - mse: 0.1021\n",
      "epoch #439\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1147 - mse: 0.1147\n",
      "epoch #440\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0839 - mse: 0.0839\n",
      "epoch #441\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0981 - mse: 0.0981\n",
      "epoch #442\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1033 - mse: 0.1033\n",
      "epoch #443\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1063 - mse: 0.1063\n",
      "epoch #444\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0987 - mse: 0.0987\n",
      "epoch #445\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1195 - mse: 0.1195\n",
      "epoch #446\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1028 - mse: 0.1028\n",
      "epoch #447\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0944 - mse: 0.0944\n",
      "epoch #448\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0989 - mse: 0.0989\n",
      "epoch #449\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1177 - mse: 0.1177\n",
      "epoch #450\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0964 - mse: 0.0964\n",
      "epoch #451\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0968 - mse: 0.0968\n",
      "epoch #452\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1040 - mse: 0.1040\n",
      "epoch #453\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1028 - mse: 0.1028\n",
      "epoch #454\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0874 - mse: 0.0874\n",
      "epoch #455\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0987 - mse: 0.0987\n",
      "epoch #456\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0884 - mse: 0.0884\n",
      "epoch #457\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0867 - mse: 0.0867\n",
      "epoch #458\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0875 - mse: 0.0875\n",
      "epoch #459\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1228 - mse: 0.1228\n",
      "epoch #460\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1061 - mse: 0.1061\n",
      "epoch #461\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1062 - mse: 0.1062\n",
      "epoch #462\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0952 - mse: 0.0952\n",
      "epoch #463\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1077 - mse: 0.1077\n",
      "epoch #464\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1059 - mse: 0.1059\n",
      "epoch #465\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1102 - mse: 0.1102\n",
      "epoch #466\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1103 - mse: 0.1103\n",
      "epoch #467\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1076 - mse: 0.1076\n",
      "epoch #468\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0848 - mse: 0.0848\n",
      "epoch #469\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0968 - mse: 0.0968\n",
      "epoch #470\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1020 - mse: 0.1020\n",
      "epoch #471\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0966 - mse: 0.0966\n",
      "epoch #472\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0870 - mse: 0.0870\n",
      "epoch #473\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0832 - mse: 0.0832\n",
      "epoch #474\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0874 - mse: 0.0874\n",
      "epoch #475\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0846 - mse: 0.0846\n",
      "epoch #476\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0807 - mse: 0.0807\n",
      "epoch #477\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0917 - mse: 0.0917\n",
      "epoch #478\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1066 - mse: 0.1066\n",
      "epoch #479\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0938 - mse: 0.0938\n",
      "epoch #480\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0890 - mse: 0.0890\n",
      "epoch #481\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0980 - mse: 0.0980\n",
      "epoch #482\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0934 - mse: 0.0934\n",
      "epoch #483\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1155 - mse: 0.1155\n",
      "epoch #484\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1020 - mse: 0.1020\n",
      "epoch #485\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0938 - mse: 0.0938\n",
      "epoch #486\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1050 - mse: 0.1050\n",
      "epoch #487\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0938 - mse: 0.0938\n",
      "epoch #488\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0930 - mse: 0.0930\n",
      "epoch #489\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0893 - mse: 0.0893\n",
      "epoch #490\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1058 - mse: 0.1058\n",
      "epoch #491\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0984 - mse: 0.0984\n",
      "epoch #492\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0961 - mse: 0.0961\n",
      "epoch #493\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0929 - mse: 0.0929\n",
      "epoch #494\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0985 - mse: 0.0985\n",
      "epoch #495\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0960 - mse: 0.0960\n",
      "epoch #496\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0951 - mse: 0.0951\n",
      "epoch #497\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0922 - mse: 0.0922\n",
      "epoch #498\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0934 - mse: 0.0934\n",
      "epoch #499\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0908 - mse: 0.0908\n",
      "CPU times: user 58.8 s, sys: 51.5 s, total: 1min 50s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train in batch sizes of 128.\n",
    "BATCH_SIZE = batch_size\n",
    "NUM_EPOCHS = 500\n",
    "NUM_CHUNKS = tss.num_chunks()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('epoch #{}'.format(epoch))\n",
    "    for i in range(NUM_CHUNKS):\n",
    "        X, y = tss.get_chunk(i)\n",
    "        \n",
    "        # model.fit does train the model incrementally. ie. Can call multiple times in batches.\n",
    "        # https://github.com/keras-team/keras/issues/4446\n",
    "        history = model.fit(x=X, y=y, batch_size=BATCH_SIZE)\n",
    "        \n",
    "    # shuffle the chunks so they're not in the same order next time around.\n",
    "    tss.shuffle_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.0908333882689476], 'mse': [0.0908333882689476]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 files.\n",
      "ts_val_data/ts_file_0.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the validation set.\n",
    "#\n",
    "# Create the validation CSV like we did before with the training.\n",
    "gross_amount_val = df_val['gross_amount'].values\n",
    "gross_amount_val_scaled = scaler.transform(gross_amount_val.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "display(gross_amount_val_scaled.shape)\n",
    "\n",
    "history_length = 3  # The history length in minutes.\n",
    "step_size = 1  # The sampling rate of the history. Eg. If step_size = 1, then values from every minute will be in the history.\n",
    "                #                                       If step size = 10 then values every 10 minutes will be in the history.\n",
    "target_step = 0  # The time step in the future to predict. Eg. If target_step = 0, then predict the next timestep after the end of the history period.\n",
    "#                   #                                             If target_step = 10 then predict 10 timesteps the next timestep (11 minutes after the end of history).\n",
    "\n",
    "# The csv creation returns the number of rows and number of features. We need these values below.\n",
    "num_timesteps = create_ts_files(gross_amount_val_scaled, start_index=0, end_index=None, history_length=history_length, step_size=step_size, \n",
    "                                target_step=target_step, num_rows_per_file=batch_size*1, data_folder='ts_val_data')\n",
    "\n",
    "num_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 1)\n",
      "validation mean squared error: 146517.85518546263\n",
      "    x_lag_3   x_lag_2   x_lag_1         y\n",
      "0  0.222222  0.000000  0.005556  0.005556\n",
      "1  0.000000  0.005556  0.005556  0.222222\n",
      "2  0.005556  0.005556  0.222222  0.000000\n",
      "3  0.005556  0.222222  0.000000  0.005556\n"
     ]
    }
   ],
   "source": [
    "# If we assume that the validation dataset can fit into memory we can do this.\n",
    "df_val_ts = pd.read_pickle('ts_val_data/ts_file_0.pkl')\n",
    "\n",
    "\n",
    "features = df_val_ts.drop('y', axis=1).values\n",
    "features_arr = np.array(features)\n",
    "\n",
    "# reshape for input into LSTM. Batch major format.\n",
    "num_records = len(df_val_ts.index)\n",
    "features_batchmajor = features_arr.reshape(num_records, -1, 1)\n",
    "\n",
    "print(features_batchmajor.shape)\n",
    "\n",
    "\n",
    "y_pred = model.predict(features_batchmajor).reshape(-1, )\n",
    "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "y_act = df_val_ts['y'].values\n",
    "y_act = scaler.inverse_transform(y_act.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "print('validation mean squared error: {}'.format(mean_squared_error(y_act, y_pred)))\n",
    "\n",
    "print(df_val_ts)\n",
    "\n",
    "#baseline\n",
    "# y_pred_baseline = df_val_ts['x_lag11'].values\n",
    "# y_pred_baseline = scaler.inverse_transform(y_pred_baseline.reshape(-1, 1)).reshape(-1 ,)\n",
    "# print('validation baseline mean squared error: {}'.format(mean_squared_error(y_act, y_pred_baseline)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
