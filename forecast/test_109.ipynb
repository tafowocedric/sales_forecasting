{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tfv1\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv1.disable_eager_execution()\n",
    "tfv1.disable_v2_behavior()\n",
    "tfv1.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_date</th>\n",
       "      <th>gross_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>391.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>786.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     txn_date  gross_amount\n",
       "0  2020-05-19         391.5\n",
       "1  2020-06-19         365.0\n",
       "2  2020-06-26         156.0\n",
       "3  2020-07-16          75.0\n",
       "4  2020-07-17         786.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"universe_dataset.csv\", usecols=[\"gross_amount\", \"txn_date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns after removing missing values: (18, 2)\n",
      "The time series starts from:  2020-05-19 00:00:00\n",
      "The time series ends on:  2020-09-03 00:00:00\n",
      "\n",
      "\n",
      "CPU times: user 4.1 ms, sys: 9 Âµs, total: 4.11 ms\n",
      "Wall time: 3.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['txn_date'] = pd.to_datetime(df['txn_date'])\n",
    "\n",
    "df.sort_values('txn_date', inplace=True, ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print('Number of rows and columns after removing missing values:', df.shape)\n",
    "print('The time series starts from: ', df['txn_date'].min())\n",
    "print('The time series ends on: ', df['txn_date'].max())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dates: 2020-08-29 00:00:00 to 2020-09-03 00:00:00\n",
      "Validation dates: 2020-08-18 00:00:00 to 2020-08-25 00:00:00\n",
      "Train dates: 2020-05-19 00:00:00 to 2020-08-12 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8, 2), (4, 2), (6, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training, validation and test datasets.\n",
    "# Since it's timeseries we should do it by date.\n",
    "test_cutoff_date = df['txn_date'].max() - timedelta(days=7)\n",
    "val_cutoff_date = test_cutoff_date - timedelta(days=14)\n",
    "\n",
    "df_test = df[df['txn_date'] > test_cutoff_date]\n",
    "df_val = df[(df['txn_date'] > val_cutoff_date) & (df['txn_date'] <= test_cutoff_date)]\n",
    "df_train = df[df['txn_date'] <= val_cutoff_date]\n",
    "\n",
    "#check out the datasets\n",
    "print('Test dates: {} to {}'.format(df_test['txn_date'].min(), df_test['txn_date'].max()))\n",
    "print('Validation dates: {} to {}'.format(df_val['txn_date'].min(), df_val['txn_date'].max()))\n",
    "print('Train dates: {} to {}'.format(df_train['txn_date'].min(), df_train['txn_date'].max()))\n",
    "\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    if isinstance(series, pd.DataFrame):\n",
    "        series = series[\"gross_amount\"].values\n",
    "    \n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "       \n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "#     ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
    "    \n",
    "    return ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Variables\n",
    "batch_size = 5\n",
    "window_size=5\n",
    "shuffle_buffer_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "\n",
    "X = tfv1.placeholder(tf.float32, [None, batch_size, 1])\n",
    "y = tfv1.placeholder(tf.float32, [None, batch_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=60, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=[None, 1]),\n",
    "\n",
    "        tf.keras.layers.LSTM(60, return_sequences=True),\n",
    "        tf.keras.layers.LSTM(60, return_sequences=True),\n",
    "        \n",
    "        tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "\n",
    "        tf.keras.layers.Lambda(lambda x: x * 400)])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vegas/anaconda3/envs/deeplearning/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# construct the model\n",
    "logits = create_model()(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.keras.losses.mean_squared_error(y, logits)\n",
    "optimizer = tfv1.train.AdamOptimizer()\n",
    "\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluation model \n",
    "correct_pred = tf.equal(y, logits)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# initialize the variable (i.e assign their default values)\n",
    "init = tfv1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134147.73    24400.607    5518.2944 623343.9      6858.451 ]\n",
      " [ 24749.979    4736.143  604131.5      5019.226  926342.56  ]\n",
      " [  5834.1943 606796.2      3941.216  913663.6    245980.1   ]]\n",
      "0.0\n",
      "Optimization Finished\n"
     ]
    }
   ],
   "source": [
    "sess_config = tfv1.ConfigProto(allow_soft_placement=True, gpu_options=tfv1.GPUOptions(per_process_gpu_memory_fraction=0.5, allow_growth=True))\n",
    "        \n",
    "\n",
    "train_set = windowed_dataset(df_train, window_size, batch_size, shuffle_buffer_size)\n",
    "iterator = tfv1.data.make_initializable_iterator(train_set)\n",
    "\n",
    "test_set = windowed_dataset(df_test, 3, batch_size, shuffle_buffer_size)\n",
    "test_iterator = tfv1.data.make_initializable_iterator(test_set)\n",
    "\n",
    "print_terminal = \"Step {}, Minibatch Loss = {:.4f}, Training Loss {:.3f}\"\n",
    "    \n",
    "# start training\n",
    "with tfv1.Session(config=sess_config) as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    for step in range(1, 5):\n",
    "        try:\n",
    "            while True:\n",
    "                x_batch_train, y_batch_train = sess.run(iterator.get_next())\n",
    "                \n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(train_op, feed_dict={X: x_batch_train, y: y_batch_train})\n",
    "                \n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: x_batch_train, y: y_batch_train})\n",
    "                print(loss)\n",
    "                print(acc)\n",
    "#                 print(print_terminal.format(step, float(loss), float(acc)))\n",
    "                \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "    \n",
    "    print(\"Optimization Finished\")\n",
    "    \n",
    "#     # Calculate accuracy \n",
    "#     sess.run(iterator.initializer)\n",
    "    \n",
    "#     while True:\n",
    "#         for x_batch_test, y_batch_test in sess.run(test_iterator.get_next()):\n",
    "#             print(\"Testing Accuracy: \", sess.run(accuracy, feed_dict={X: x_batch_test, y: y_batch_test}))\n",
    "\n",
    "#     except tf.errors.OutOfRangeError:\n",
    "#         pass       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
