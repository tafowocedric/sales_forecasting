{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from ast import literal_eval\n",
    "import json\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import zscore\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "\n",
    "%matplotlib inline\n",
    "# plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres username, password, and database name\n",
    "POSTGRES_ADDRESS = 'localhost'\n",
    "\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_USERNAME = 'vegas'\n",
    "POSTGRES_PASSWORD = 'VrichCrich99'\n",
    "POSTGRES_DBNAME = 'univers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME, password=POSTGRES_PASSWORD, ipaddress=POSTGRES_ADDRESS, port=POSTGRES_PORT, dbname=POSTGRES_DBNAME))\n",
    "cnx = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color: red; font-size: 2em'>Fetch user data according to data count</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appstech_labs_id = 1 # user id for fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a fetching function according to the appstech_labs_user data size\n",
    "def fetch_data(_id, small_data_size, medium_data_size, large_data_size):\n",
    "    return pd.read_sql_query(f\"SELECT * FROM user_sales_table WHERE appstech_labs_id='{appstech_labs_id}'\", cnx, index_col='txn_date', parse_dates=['txn_date'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_data(appstech_labs_id, small_data_size=530234, medium_data_size=1530234, large_data_size=2203234)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color: red; font-size: 2em'>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_numeric_features(df):\n",
    "    numeric_feats = df.dtypes[df.dtypes != 'object'].index\n",
    "    numeric_feats = numeric_feats[1:]\n",
    "    return numeric_feats\n",
    "\n",
    "numeric_feats = get_all_numeric_features(df)\n",
    "numeric_feats = numeric_feats[:-1]\n",
    "numeric_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat = df[numeric_feats].corr()\n",
    "plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(cormat, vmax=0.9, square=True, cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color: red; font-size: 2em'>Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "def feature_importance(features, df, threshold, *args, **kwargs):\n",
    "    '''args, kwargs pass True or include=True for additional features'''\n",
    "    important_feature = list()\n",
    "    cormat = df[features].corr()\n",
    "    \n",
    "    if kwargs.get('include') or args:\n",
    "        if kwargs.get('include') or args[0]:\n",
    "            include = ['qty', 'margin']\n",
    "            for expt in include:\n",
    "                important_feature.append(expt)\n",
    "    \n",
    "    for feat in features:\n",
    "        if cormat[f\"{feat}\"][-3] > threshold:\n",
    "            important_feature.append(feat)\n",
    "            \n",
    "    return important_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = feature_importance(numeric_feats, df, 0.69, False)\n",
    "df_feats = df.copy()\n",
    "df_feats = df_feats[imp_features]\n",
    "df_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat = df_feats[imp_features].corr()\n",
    "plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(cormat, vmax=0.9, square=True, cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color: red; font-size: 2em'>Check For Null Values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_null_values(df, labels, target, model):\n",
    "    data_with_null = df[labels].dropna()\n",
    "    data_without_null = data_with_null.dropna()\n",
    "    \n",
    "    # all features except target\n",
    "    train_data_x = data_without_null.drop(target, axis=1).values\n",
    "    train_data_y = data_without_null[f\"{target}\"].values.reshape(-1, 1)\n",
    "    \n",
    "    model.fit(X=train_data_x, y=train_data_y) # training the model\n",
    "\n",
    "    test_data = data_with_null.drop(target, axis=1) #\n",
    "    yhat = model.predict(test_data)\n",
    "        \n",
    "    newdf = pd.DataFrame(yhat, columns=[target])\n",
    "    # replace only the null values\n",
    "    data_with_null[target].fillna(newdf[target], inplace=True)\n",
    "    \n",
    "    return data_with_null[target]\n",
    "    \n",
    "    \n",
    "def handle_missing_value(df, features, *args, **kwargs):\n",
    "    linreg = LinearRegression()\n",
    "    \n",
    "    if kwargs.get('drop_column'):\n",
    "        return df.drop(features, axis=1)\n",
    "    \n",
    "    for feat in features:\n",
    "        null_count = df[feat].isnull().sum()\n",
    "        \n",
    "        if null_count > 1 and null_count < int(len(df[feat]) * 10 / 100): # full missing values with mean()\n",
    "            if df[feat].dtype == 'object':\n",
    "                df[feat] = df[feat].fillna(df[feat].mode())\n",
    "            else:\n",
    "                df[feat] = df[feat].fillna(df[feat].mean())\n",
    "            \n",
    "        elif null_count >= int(len(df[feat]) * 10 / 100) and null_count < int(len(df[feat]) * 20 / 100): # random generate missing values\n",
    "            technique = [df[feat].fillna(df[feat].mean()), df[feat].fillna(df[feat].median()), df[feat].fillna(df[feat].mode())]\n",
    "            index = np.random.choice([0, 1, 2], p=[0.34, 0.33, 0.33])\n",
    "            df[feat] = technique[index]\n",
    "            \n",
    "        elif null_count >= int(len(df[feat]) * 20 / 100) and null_count < int(len(df[feat]) * 40 / 100): # predict missing values if selected else random generate\n",
    "            if kwargs.get('use_model') or args:\n",
    "                if kwargs.get('use_model') or args[0]:\n",
    "                    generate_null = generate_null_values(df, features, feat, linreg)\n",
    "                    df[feat] = generate_null[~generate_null.index.duplicated()]\n",
    "            else:\n",
    "                technique = [df[feat].fillna(df[feat].mean()), df[feat].fillna(df[feat].median()), df[feat].fillna(df[feat].mode())]\n",
    "                index = np.random.choice([0, 1, 2], p=[0.34, 0.33, 0.33])\n",
    "                df[feat] = technique[index]\n",
    "        \n",
    "        elif null_count >= int(len(df[feat]) * 40 / 100): # worst case senario\n",
    "            df = df.drop(feat, axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = handle_missing_value(df_feats, imp_features, True)\n",
    "df_feats.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color: red; font-size: 2em'>Target Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle outliers\n",
    "def handleOutliers(df, threshold):    \n",
    "    z = np.abs(zscore(df))\n",
    "    \n",
    "    return df[(z < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_outliers = handleOutliers(df_feats, 3)\n",
    "print(df_feats_outliers.shape)\n",
    "df_feats_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_feats_outliers['gross_amount'])\n",
    "plt.show()\n",
    "plt.hist(df_feats_outliers['gross_amount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_feats_outliers.copy()\n",
    "new_df = new_df\n",
    "\n",
    "new_df = new_df.rename_axis('ds')\n",
    "new_df = new_df.rename(columns={'gross_amount': 'y'})\n",
    "new_df = new_df.drop(['sales_tax_amount', 'margin'], axis=1)\n",
    "new_df = new_df.reset_index()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_train = new_df[:20]\n",
    "fb_test = new_df[len(fb_train):]\n",
    "\n",
    "print(fb_train.shape, fb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(fb_train)\n",
    "future = m.make_future_dataframe(periods=len(fb_test))\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fb_test)\n",
    "# forecast['yhat'][-len(fb_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(fb_test['y'].values, forecast['yhat'][-len(fb_test):].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_events = pd.read_csv(\"data/datasets_holidays_events.csv\")\n",
    "df_holidays_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = df_holidays_events[df_holidays_events['transferred'] == False][['description', 'date']]\n",
    "holidays.columns = ['holiday', 'ds']\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(holidays=holidays)\n",
    "# m.add_seasonality(name='monthyly', period=3, fourier_order=1)\n",
    "m.fit(fb_train)\n",
    "future = m.make_future_dataframe(periods=len(fb_test), freq=\"D\", include_history=True)\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(fb_test['y'].values, forecast['yhat'][-len(fb_test):].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fb_test)\n",
    "# forecast['yhat'][-len(fb_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fb_test['y'].values)\n",
    "plt.plot(forecast['yhat'][-len(fb_test):].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 2.5 # learning rate for scipy stats.\n",
    "\n",
    "def normalize_value(df, features, norm_type, boxcox):\n",
    "    return {\n",
    "        \"log1p_skew\": np.log1p(df[features]), # inverse np.exp\n",
    "        \"sqrt_skew\": np.sqrt(df[features]), # inverse x**-1/2\n",
    "#         \"stats_skew\": boxcox(df[features], LAMBDA) # inverse inv_boxcox(state, 2.5)\n",
    "    }.get(norm_type)\n",
    "\n",
    "\n",
    "def inverser_normalize_value(df, features, norm_type, *args, **kwargs):\n",
    "    return {\n",
    "        \"log1p_skew\": np.exp(df[features]), # inverse np.exp\n",
    "        \"sqrt_skew\": df[features] * df[features], # inverse x**-1/2\n",
    "#         \"stats_skew\": inv_boxcox(df[features], kwargs.get(\"lambda\")) # inverse inv_boxcox(state, 2.5)\n",
    "    }.get(norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization for\n",
    "\n",
    "def normalize_data(df, features, *arg, **kwargs):\n",
    "    new_df = pd.DataFrame(columns=['features', 'log1p_skew', 'sqrt_skew']) #, 'stats_skew'\n",
    "    \n",
    "    for feat in features:\n",
    "        try:\n",
    "            sqrt = np.sqrt(df[feat])\n",
    "            log1p = np.log1p(df[feat])\n",
    "#             stats = pd.Series(boxcox(df[feat], LAMBDA))\n",
    "        \n",
    "        except ValueError:\n",
    "#             stats = np.NaN\n",
    "            pass\n",
    "    \n",
    "        new_df = new_df.append({'features': feat, 'log1p_skew': log1p.skew(), 'log1p_': log1p.isna().sum(), 'sqrt_skew': sqrt.skew(), 'sqrt_': sqrt.isna().sum()}, ignore_index=True)\n",
    "#     'stats_skew': stats.skew(), 'stats_': stats.isna().sum(),\n",
    "\n",
    "    new_df = new_df.groupby(['features']).sum()\n",
    "    if new_df['log1p_'].values.sum() > 0:\n",
    "        new_df = new_df.drop(['log1p_', 'log1p_skew'], axis=1)\n",
    "    if new_df['sqrt_'].values.sum() > 0:\n",
    "        new_df = new_df.drop(['sqrt_', 'sqrt_skew'], axis=1)\n",
    "#     if new_df['stats_'].values.sum() > 0:\n",
    "#         new_df = new_df.drop(['stats_', 'stats_skew'], axis=1)\n",
    "        \n",
    "    if new_df.empty:\n",
    "        return None, df\n",
    "    print(new_df)\n",
    "    arg_norm_score_obj = list()\n",
    "    for i in range(new_df.shape[1]):\n",
    "        arg_norm_score_obj.append({\"name\": f\"{new_df.columns[i]}\", \"score\": new_df[f\"{new_df.columns[i]}\"].sum()})\n",
    "        \n",
    "    NORM_TYPE = min(i.get('name') for i in arg_norm_score_obj if i.get('score') > 0) # global variable ->>\n",
    "    \n",
    "    norm_val = normalize_value(df, features, NORM_TYPE, boxcox)\n",
    "    return NORM_TYPE, norm_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORM_TYPE, df_feats_norm = normalize_data(df_feats_outliers, ['gross_amount'])\n",
    "print(NORM_TYPE)\n",
    "df_feats_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_price = pd.read_csv('data/train.csv')\n",
    "# print(house_price.shape)\n",
    "# house_price = handle_missing_value(house_price, house_price.columns, True)\n",
    "# house_price_outliers = handleOutliers(house_price[house_price.dtypes[house_price.dtypes != \"object\"].index], 3)\n",
    "# NORM_TYPE_1, house_pricing_norm = normalize_data(house_price_outliers, house_price_outliers.columns) # global variable for NORM_TYPE ->>\n",
    "# print(NORM_TYPE_1)\n",
    "# house_pricing_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontally stack columns\n",
    "df_feats_norm = df_feats_norm.set_index(df_feats_norm.index).resample(\"D\")[df_feats_norm.columns].sum()\n",
    "series = df_feats_norm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = series[:-20], series[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    # flatten data\n",
    "    data = np.array(history)\n",
    "#     data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    # retrieve last observationmetricsor input data\n",
    "    input_x = data[-n_input:, :]\n",
    "    # reshape into [1, n_input, n]\n",
    "    input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    # forecast the next week\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    # we only want the vector forecast\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "    # history is a list of weekly data\n",
    "    history = [x for x in train]\n",
    "    # walk-forward validation over each week\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        # predict the week\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        # store the predictions\n",
    "        predictions.append(yhat_sequence)\n",
    "        # get real observation and add to history for predicting the next week\n",
    "        history.append(test[i, :])\n",
    "    # evaluate predictions days for each week\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(dataset, n_input, n_out):\n",
    "    # flatten data\n",
    "    X, y = list(), list()\n",
    "\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(dataset)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "\n",
    "        if out_end <= len(dataset):\n",
    "            X.append(dataset[in_start: in_end, :])\n",
    "            y.append(dataset[in_end: out_end, -1])\n",
    "\n",
    "        in_start += 1\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = to_supervised(train, 1, 1)\n",
    "train_y = train_y.reshape(-1, 1)\n",
    "train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(52, activation='relu', input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(RepeatVector(train_y.shape[1]))\n",
    "\n",
    "model.add(TimeDistributed(Dense(10, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(train_y.shape[1])))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(train_y.shape[1]))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit network\n",
    "model.fit(train_x, train_y, epochs=200, batch_size=17, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = to_supervised(test, 1, 1)\n",
    "test_y = test_y.reshape(-1, 1)\n",
    "test_y = test_y.reshape((test_y.shape[0], test_y.shape[1], 1))\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "\n",
    "predictions = evaluate_model(train, test, 1)\n",
    "predictions = predictions.reshape(predictions.shape[0] * predictions.shape[1], predictions.shape[2])\n",
    "\n",
    "r2_score(np.array(test[:, -1]), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    print(np.array(test[i, -1]), predictions[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA, ARMAResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "        \n",
    "    return diff\n",
    "\n",
    "def inverse_differece(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_len = int(len(series) * 0.97)\n",
    "train, test = series[:train_len], series[train_len:]\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# history = [x for x in train[:, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    train_size = int(len(X) * 0.79)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0, solver='lbfgs')\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    print(r2_score(test, predictions))\n",
    "    \n",
    "    plt.plot(predictions, color='red')\n",
    "    plt.plot(test)\n",
    "    plt.show()\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "prediction = evaluate_arima_model(series[:, -1], (4, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    mse = evaluate_arima_model(dataset, order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from time import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# solvers\n",
    "solvers = ['lbfgs', 'powell']\n",
    "\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# evaluate_models(series[:, -1], p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "4, 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "history = [x for x in train[:, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test[:, -1], prediction)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "print(r2_score(test[:, -1], prediction))\n",
    "plt.plot(test[:, -1])\n",
    "plt.plot(prediction, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "residuals = [test[i, -1] - prediction[i] for i in range(len(test))]\n",
    "residuals = pd.DataFrame(residuals)\n",
    "\n",
    "residuals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "residuals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "residuals.hist(ax=plt.gca())\n",
    "plt.subplot(212)\n",
    "residuals.plot(kind='kde', ax=plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_fit.forecast()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
